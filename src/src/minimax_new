def minimax(state, heights, current_player, depth, alpha=-np.inf, beta=np.inf, maximizing_player=True):
    env = Connect4BitboardEnv()
    env.board = state
    env.heights = heights.copy()
    env.current_player = current_player

    if depth == 0 or env._check_win(state[0]) or env._check_win(state[1]):
        if env._check_win(state[0]):
            return 1 if maximizing_player else -1
        if env._check_win(state[1]):
            return -1 if maximizing_player else 1
        return 0  # Draw or depth limit reached

    if maximizing_player:
        max_eval = -np.inf
        for action in env.get_possible_moves():
            new_board = list(state)
            move = 1 << (action * (env.board_height + 1) + heights[action])
            new_board[current_player] ^= move
            heights[action] += 1

            eval = minimax(tuple(new_board), heights, 1 - current_player, depth - 1, alpha, beta, False)
            max_eval = max(max_eval, eval)
            alpha = max(alpha, eval)
            heights[action] -= 1

            if beta <= alpha:
                break
        return max_eval
    else:
        min_eval = np.inf
        for action in env.get_possible_moves():
            new_board = list(state)
            move = 1 << (action * (env.board_height + 1) + heights[action])
            new_board[current_player] ^= move
            heights[action] += 1

            eval = minimax(tuple(new_board), heights, 1 - current_player, depth - 1, alpha, beta, True)
            min_eval = min(min_eval, eval)
            beta = min(beta, eval)
            heights[action] -= 1

            if beta <= alpha:
                break
        return min_eval

def minimax_opponent_policy(state, heights, current_player, depth=3):
    best_action = None
    best_value = -np.inf if current_player == 1 else np.inf

    for action in range(7):
        if heights[action] < 6:
            new_board = list(state)
            move = 1 << (action * (6 + 1) + heights[action])
            new_board[current_player] ^= move
            heights[action] += 1

            move_value = minimax(tuple(new_board), heights, 1 - current_player, depth - 1, maximizing_player=(current_player == 0))
            heights[action] -= 1

            if (current_player == 0 and move_value > best_value) or (current_player == 1 and move_value < best_value):
                best_value = move_value
                best_action = action

    action_probs = {action: 0.0 for action in range(7)}
    if best_action is not None:
        action_probs[best_action] = 1.0

    return action_probs